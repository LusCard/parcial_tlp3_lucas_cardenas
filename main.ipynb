{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fee5ee9",
   "metadata": {},
   "source": [
    "# Examen Parcial n°1 2da Parte - TLP3 - Python para Ciencia de Datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999099d0",
   "metadata": {},
   "source": [
    "**A partir del datasets brindado, realizar los siguientes procedimientos:**\n",
    "\n",
    "* Importar datasets con Pandas.\n",
    "* Explorar los datos con los metodos correspondientes. \n",
    "* Limpieza de los datos (Normalización de datos).\n",
    "* Obtener estadisticas.\n",
    "* Mostrar los datos procesados con graficos utilizando la libreria Matplotlib.\n",
    "* Exportar el contenido a un archivo sqlite utilizando PANDAS.\n",
    "\n",
    "\n",
    "**Importante: Se debe documentar cada procedimiento realizado, siguiendo la siguiente estructura:**\n",
    "\n",
    "1. Celda de Markdown (Documentación)\n",
    "2. Código (Sin comentarios, se debe documentar lo sufiente solo en la celda de markdown).\n",
    "\n",
    "\n",
    "### Criterios de Evaluación:\n",
    "\n",
    "1. No esta permitido el uso de IAs durante el examen. (Desactivar Copilot o cualquier herramienta de IA para autocompletar codigo.)\n",
    "\n",
    "2. Se deben utilizar nombres de variables descriptivos y claros (Utilizar la nomeclatura correspondiente para los nombres de variables).\n",
    "\n",
    "3. Comentarios claros y concisos que expliquen el propósito de cada sección del código en una celda de markdown antes del código.\n",
    "\n",
    "4. Utilizar mensajes de commit descriptivos. (Puedes utilizar la extension CONVENTIONAL COMMIT de VS-CODE).\n",
    "\n",
    "5. Entrega en tiempo y forma (Parciales entregados fuera de hora o con commits pasados el horario de entrega quedará invalidado.)\n",
    "\n",
    "6. Todo el código desarrollado debe ser subido a un repositorio en GitHub (el nombre del repositorio de seguir la siguiente estructura: \n",
    "**parcial1_tlp3_nombre_apellido**).\n",
    "\n",
    "7. Para resolver las actividades se debe insertar casillas de codigo entre cada actividad del cuaderno de Jupyter.\n",
    "\n",
    "8. Deben trabajar con el datasets adjunto.\n",
    "\n",
    "9. Una vez finalizado el examen, los resultados deben quedar guardados debajo de cada celda (NO EJECUTAR LA OPCIÓN \"borrar todas las salidas\").\n",
    "\n",
    "**Importante:** Una vez finalizado el examen, marcar como completado en el classroom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a34b8",
   "metadata": {},
   "source": [
    "## Actividades: \n",
    "### 1. Importación del Dataset con Pandas\n",
    "\n",
    "En esta sección, se debe utilizar la librería Pandas para cargar el archivo CSV que contiene los datos de VOTACIONES en un Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2295cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_votaciones = pd.read_csv('votaciones.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b2f9b",
   "metadata": {},
   "source": [
    "Lectura de dataset con pandas con \".read_csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794780ef",
   "metadata": {},
   "source": [
    "### 2. Exploración Inicial de los Datos\n",
    "\n",
    "A continuación, se deben emplear métodos de Pandas para obtener una visión general del dataset. \n",
    "- 2.1: Visualizar las primeras filas y ultimas.\n",
    "- 2.2: Obtener informacion del df con su metodo correspondiente.\n",
    "- 2.3: Hacer un conteo de valores nulos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0984148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 10 filas      nombre apellido         dni     provincia  voto fecha_votacion\n",
      "0   pánfilo    pombo  34787190.0  buenos aires  nulo     2024-11-22\n",
      "1    albina  heredia  48336819.0      santa fe  nulo     2024-04-24\n",
      "2       NaN   solano  49179364.0       neuquen  nulo     2024-05-20\n",
      "3    salomé   barrio  43725639.0  buenos aires   NaN     05-06-2024\n",
      "4    matías  esteban  30599927.0         chaco    no     10-07-2023\n",
      "5       NaN     sosa  17014535.0      santa fe    sí     02-11-2024\n",
      "6  gervasio      bou  33761658.0       mendoza    no     23-09-2023\n",
      "7   brígida   angulo  22169546.0         chaco    no     2024-05-02\n",
      "8    glauco    fabra         NaN       cordoba    sí     07-06-2023\n",
      "9  trinidad  company  12192872.0       neuquen  nulo     30-10-2024\n",
      "-----------------------------------------\n",
      "Ultimas 10 filas         nombre  apellido         dni     provincia  voto fecha_votacion\n",
      "91        alma   pereyra  11121314.0       mendoza    no     17-09-2023\n",
      "92   alejandro     bazan  12131415.0         chaco  nulo     16-09-2023\n",
      "93      marcos  villalba         NaN         salta    sí     15-09-2023\n",
      "94      yesica    ospina  13141516.0  buenos aires    no     2023-09-14\n",
      "95     leandro    torres  14151617.0       cordoba    sí     13-09-2023\n",
      "96       carla     vidal  15161718.0      misiones  nulo     2023-09-12\n",
      "97    federico   barrios  16171819.0       neuquen    no     11-09-2023\n",
      "98       belen      vera  17181920.0       tucuman    sí     2023-09-10\n",
      "99     gustavo     gauna  18192021.0      santa fe  nulo     09-09-2023\n",
      "100      rocio     avila  19202122.0       formosa    no     08-09-2023\n",
      "-----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   nombre          91 non-null     object \n",
      " 1   apellido        94 non-null     object \n",
      " 2   dni             90 non-null     float64\n",
      " 3   provincia       95 non-null     object \n",
      " 4   voto            96 non-null     object \n",
      " 5   fecha_votacion  95 non-null     object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 4.9+ KB\n",
      "Información básica del dataframe None\n",
      "-----------------------------------------\n",
      "Cantidad de nulos en todo el DF nombre            10\n",
      "apellido           7\n",
      "dni               11\n",
      "provincia          6\n",
      "voto               5\n",
      "fecha_votacion     6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2.1\n",
    "\n",
    "print(\"Primeras 10 filas\",df_votaciones.head(10))\n",
    "print(\"-----------------------------------------\")\n",
    "print(\"Ultimas 10 filas\", df_votaciones.tail(10))\n",
    "print(\"-----------------------------------------\")\n",
    "#2.2\n",
    "print(\"Información básica del dataframe\",df_votaciones.info())\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "#2.3\n",
    "print(\"Cantidad de nulos en todo el DF\",df_votaciones.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c23b0",
   "metadata": {},
   "source": [
    "### 3. Limpieza y Normalización de los Datos\n",
    "\n",
    "- 3.1. Esta etapa crucial deben aplicar la corrección de diversos errores presentes en el dataset. Se abordarán los valores faltantes (Deben aplicar los metodos que ustedes crean convenientes **(Solo 1)**, por ejemplo: Eliminación de filas, cubrir valores con media, mediana, etc.)\n",
    "- 3.2: La columna Fecha deberan pasarla al tipo datetime con su metodo correspondiente.\n",
    "- 3.3: Corregir las mayusculas en el caso de Nombre y Apellido (Si es que corresponde.)\n",
    "- 3.4: En el caso de los votos, aplicar mayusculas a cada fila.\n",
    "- 3.5 EL campo DNI debe ser del tipo INT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13928805",
   "metadata": {},
   "source": [
    "### 4. Obtención de Estadísticas Descriptivas\n",
    "\n",
    "Después de la limpieza, deben hacer lo siguiente: \n",
    "\n",
    "- 4.1: calcular nuevamente las estadísticas descriptivas para observar el impacto del proceso de limpieza en los datos numéricos.\n",
    "- 4.2: Calcular estadísticas específicas por grupo (Agrupar dos columnas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db32f72",
   "metadata": {},
   "source": [
    "### 5. Visualización de los Datos con Matplotlib\n",
    "\n",
    "En esta sección, deben utilizar la librería Matplotlib para crear **UNA** visualización que permitan comprender mejor los datos de ventas.El grafico es a elección, puede crear **UNO** de los siguientes: histogramas, diagramas de dispersión, gráficos de barras y graficos de torta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd91f969",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 6. Exportación a Archivo SQLite\n",
    "\n",
    "Finalmente, deben utilizar la funcionalidad de Pandas para guardar el DataFrame procesado en una base de datos SQLite. Deben hacer una conexión y hacer una consulta para ver si los datos fueron cargados correctamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a704ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
